\documentclass{llncs}

\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
%% \usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{blindtext}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage[normalem]{ulem}
\usepackage{listings}
\usepackage[export]{adjustbox}
\usepackage{lscape}
\usepackage{float}
\usepackage{booktabs}

%% \usepackage{pdftricks}
%% \begin{psinputs}
%%   \usepackage{pstricks}
%% \end{psinputs}
%% \usepackage[pdf]{pstricks}

\usepackage{float}
\usepackage[hypertexnames=false]{hyperref}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\floatname{algorithm}{Pseudocode}

\usepackage{cleveref}
\usepackage{tikz}
\usetikzlibrary{matrix,shapes,arrows,positioning,chains}
\usepackage{hhline}
\usepackage{multirow}

\pagestyle{plain}

%%%%
\include{macro}
%%%%
\subtitle{A distribuited algorithm\\for the subgraph isomorphism problem}
\title{Analisi dei requisiti}
\author{Anna Becchi, Idriss Riouak}
\institute{Laurea Magistrale in Informatica\\Universit\`a di Udine, Italy}
\date{A.A. 2017/2018}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%\begin{titlingpage}
\maketitle
\begin{abstract}
In letteratura il problema del \emph{subgraph isomorphism}
centralizzato è stato ampiamente studiato. Ciononostante è difficile
trovare studi relativi alla stessa problematica su sistemi distribuiti.
L'obiettivo della seguente analisi è fornire un algoritmo distribuito
per il \emph{subgraph isomorphism} individuandone le criticità e
problematiche, descrivendo dunque i requisiti funzionali e non
funzionali del sistema come ad esempio la \emph{tolleranza ai
guasti} e \emph{consistenza} delle strutture dati.
\end{abstract}
%\end{titlingpage}

\section{Introduzione}
Il \emph{subgraph isomorphism} ha diverse applicazioni nello contesto
dei sistemi distribuiti, in particolare considereremo il caso in cui  un insieme
di \emph{robot} con \emph{sensori wireless} viene posizionato all'interno di
un edificio in maniera casuale. Tali robot hanno una visione parziale dell'edificio
e sono in grado di comunicare unicamente attraverso scambio di messaggi.
Dunque dato un percorso l'obiettivo finale è quello di determinare se esiste
solamente attraverso la conoscenza parziale dei robot.

\subsection{Modellazione del problema}
Dato un grafo $\cG = ( \Vset, E)$, $\Vset = \{v_i\}_{i \in V}$,
che rappresenta la mappa di un edificio, viene inizializzato un
insieme di processi $\Sset = \{s_i \}_{i \in S}$ con $S$ insieme
random $S \sseq V$.
Tali processi simulano l'insieme dei robot che
acquisiscono, durante la fase di inizializzazione, una conoscenza
parziale del luogo. L'acquisizione di nuova conoscenza corrisponde
alla memorizzazione in ogni $s_i$ della lista di adiacenza del nodo
corrispondente $v_i \in \Vset$.
Inizialmente dunque il raggio di conoscenza di ogni sensore corrisponde
a un solo arco del grafo.

Inoltre potrà essere simulato anche il loro spostamento e la progressiva
acquisizione di nuova conoscenza del grafo, compatibilmente con le
loro (limitate) capacità di memorizzazione.

L'algoritmo viene innescato da una query $\cQ = (\Vset_\cQ, E_\cQ)$, 
che viene divulgata alla rete di processi: l'obiettivo sarà verificare
nel grafo $\cG$ l'esistenza di un sottografo corrispondente a $\cQ$,
evitando di ricostruire la conoscenza totale e centralizzata del
grafo stesso.

Considereremo black-box tutti gli aspetti legati all'acquisizione delle informazioni
da parte dei robot, focalizzando l'attenzione sull'astrazione matematica.



\subsection{Ambiente di sviluppo}
L'ambiente di sviluppo è stato scelto in modo tale da poter evidenziare solamente
le caratteristiche più rilevanti del problema.
Si è scelto di utilizzare il \emph{Akka}: un toolkit per la creazione di applicazioni
distribuite e concorrenti con supporto alla \emph{fault-tollerance event-driven}.
Il toolkit è disponibile sia per il linguaggio imperativo \emph{Java} che per il
funzionale \emph{Scala}.

Akka si basa sulla figura degli \emph{Actor}. Un Actor è un astrazione che permette
al programmatore di focalizzare l'attenzione sugli obiettivi funzionali liberandolo
da alcune di quelle che sono le  problematiche della programmazione
concorrente e distribuita tra cui: gestione dei thread e creazioni di canali.
\subsubsection{Ipotesi sul sistema}
\label{sec:hypotesis}
Il sistema distribuito della quale stiamo fornendo la descrizione è stato progettato per funzionare
sotto determinate ipotesi quali:
\begin{itemize}
	\item il grafo $\cG = ( \Vset, E)$ rappresentante la mappa dell'edificio viene fornito dall'utente in un
	file di testo sotto forma di liste d'adiacenza,
	\item il grafo  $\cQ = (\Vset_\cQ, E_\cQ)$,  rappresentante la query viene fornito dall'utente in un
	file di testo sotto forma di liste d'adiacenza,
	\item la topologia del grafo $\cG = ( \Vset, E)$ è costante nel tempo,
	\item la possibilità che due o più robot possano trovarsi contemporaneamente sullo stesso nodo,
	\item i robot hanno limitazioni fisiche, possono memorizzare l'intera  query $\cQ$, e
	nel caso di spostamento [\ref{sec:computation}] dei sensori, sono in grado di tenere in memoria la conoscenza acquisita nello stato attuale e nel passo precedente (i.e. al secondo spostamento perdo la conoscenza acquisita
	durante l'inizializzazione). Ciò impedisce ad un sensore di ricostruire l'intero grafo $\cG$ nella sua completezza.
	\item \coanote{Definire le ipotesi sulla grandezza del grafo $\cG$!}
\end{itemize}
\section{Requisiti funzionali}
Nella seguente sezione verranno descritti quelli che sono i requisiti funzionali dell'applicativo
\subsection{Inizializzazione}
Il sistema in fase d'inizializzazione caricherà i grafi $\cG = ( \Vset, E)$ e $\cQ = (\Vset_\cQ, E_\cQ)$ dai
file forniti dall'utente. Quest'ultimo dovrà fornire in input due interi:
\begin{itemize}
\item \texttt{num\_proc:} rappresentante la cardinalità dell'insieme $\Sset$, ovvero il numero di
  robot distribuiti sulla mappa dell'edificio,
\item \texttt{num\_search\_group} (\emph{opzionale}) : rappresentante il livello di replicazione del sistema [\ref*{sec:nonfunc-req}]. Se non specificato viene posto uguale a tre.
\end{itemize}

\subsection{Computazione}
\label{sec:computation}
La query viene distribuita ad un elemento per ogni \texttt{search\_group} [\ref*{sec:nonfunc-req}],
che inizierà a cercare un match tra i grafi $\cG$ e $\cQ$. Ogni volta che un viene trovato isomorfismo
parziale tra la conoscenza del robot e la query, quest'ultima viene prima sfoltita e poi inoltrata ad
un altro elemento dello stesso \texttt{search\_group}.

Se l'esisto della computazione della query dovesse avere esito negativo,
l'utente può decidere se ritentare la stessa ricerca facendo acquisire nuova conoscenza
all'intero sistema distribuito, ciò può avvenire attraverso due modalità:
\begin{itemize}
	\item posizionamento di un nuovo robot all'interno del grafo $\cG$,
	\item muovere \emph{tutti} i robot in un nodo a loro adiacente, caricando e memorizzando
	 dal grafo $\cG$ le nuove liste d'adiacenza. Occorre tenere presente che i sensori hanno
	 una capacità di memorizzazione limitata [\ref{sec:hypotesis}] e dunque può accadere che durante
	 tale operazione vengano sovrascritte  le liste d'adiacenza dei nodi più lontani.
\end{itemize}

\subsection{Esito della computazione}
L'esito della computazione dell'algoritmo viene comunicata a video all'utente finale che può essere:
\begin{itemize}
\item \texttt{MATCH}: nel caso in cui, unicamente attraverso scambio di messaggi, i sensori riescano a trovare
  un isomorfismo parziale tra il grafo $\cG$ e il grafo $\cQ$,
\item \texttt{FAIL}: nel caso in cui non esita il match tra la mappa dell'edificio e la query,
\item \texttt{DONTKNOW}: nel caso in cui si verificasse un errore interno del sistema e
  non si riesca a determinare in maniera effettiva se esiste un isomorfismo tra i due grafi. Tale opzione
  è stata introdotta per evitare la presenza di falsi negati o falsi positivi. In tal modo garantiamo all'utente
  che i  \texttt{MATCH} o \texttt{FAIL} sono da considerarsi effettivi.
\end{itemize}

\subsection{Entità}
Nel corso dell'analisi dei requisiti del sistema, abbiamo individuato quelli che sono 
gli attori principali. Di seguito una descrizione di quest'ultimi:
\begin{itemize}
	\item 
\end{itemize}

%\subsection{Ruoli}
%In questa sezione descriviamo le caratteristiche e le funzionalità
%efferte dai principali ruoli del sistema:
%oltre ai sensori, che costituiscono la parte distribuita
%è necessario definire a priori alcuni ruoli centralizzati
%che possano essere punto di accesso all'intero cluster.%
%~\footnote{Come verrà successivamente analizzato,
%  nella Sezione~\ref{sec:nonfunc-req} questo non lede alla
%  scalabilità del sistema.}
%
%\subsubsection*{Sensore}
%I sensori vengono sparpagliati in fase di inizializzazione del
%sistema ognuno su un nodo della rete: sono in grado di
%acquisire una conoscenza parziale del grafo, assumendo che si
%riesca sempre ad acquisire correttamente tutta l'informazione
%locale al nodo su cui si trovano
%(tale fase di acquisizione verrà simultata tramite il caricamento
%della lista di adiacenza di alcuni nodi da un grafo centralizzato,
%astraendo l'implementazione dai particolari metodi di
%rilevazione e di sintesi delle informazioni).
%
%Sono in grado di muoversi e di conseguenza aumentare la loro
%conoscenza.
%
%Data la loro limitata capacità di memorizzazione,
%stimata essere \coanote{``STIMAMI!!''},
%può accadere che
%durante uno spostamento perdano conoscenza rispetto alla zona del
%grafo precedentemente esplorata.
%
%Rispetto ad un'analisi ad alto livello,
%saranno in grado di gestire messaggi del tipo:
%\begin{itemize}
%\item \texttt{try-query()}: alla ricezione della query da verificare
%  si occupa di rimuovere da questa le parti che corrispondono alla
%  sua conoscenza parziale del grafo. In questa fase può riuscire a
%  verificare la presenza dell'intera query (\emph{match}),
%  scoprire inconsistenze della query con il grafo conosciuto
%  (\emph{fail}), oppure rimanere in una fase di \emph{dontknow}
%  per cui rimangono elementi ancora da verificare: la nuova query
%  prodotta verrà rimandata al resto del cluster attivo.
%  Al termine il sensore si dichiarerà non più interessato a seguire
%  gli sviluppi di quella query, avendo già contribuito con le
%  sue conoscenze.
%\item \texttt{move()}: causa lo spostamento del sensore e il
%  conseguente caricamento di nuova conoscenza.
%\end{itemize}
%
%\subsubsection*{Accesso al cluster}
%Definiamo alcuni ruoli di accesso all'intero cluster di sensori
%che si occuperanno di:
%\begin{itemize}
%\item inizializzare il sistema distribuendo random i sensori sui
%  nodi del grafo totale;
%\item distribuire la richiesta di spostamento a tutti i sensori;
%\item aggiungere un nuovo sensore sulla mappa;
%\item iniziare una nuova ricerca;
%\item forzare la terminazione della ricerca.
%\end{itemize}
%
%\subsubsection*{Interfaccia}
%L'interfaccia con l'utente viene fornita da terminale, offrendo:
%\begin{itemize}
%\item comando caricare manualmente la mappa del grafo
%  completo (utile in fase di sperimentazione);
%\item comando per iniziare una nuova query caricandola da file:
%  la query verrà controllata perché non può richiedere una
%  memorizzazione superiore alla capacità di un singolo sensore.
%\item comando per imporre l'avanzamento di tutti i sensori;
%\item comando per l'aggiunta manuale di un nuovo sensore;
%\item restituizione del risultato (\emph{match}, \emph{fail},
%  \emph{dontknow}) all'utente.
%\end{itemize}

\section{Requisiti non funzionali}
\label{sec:nonfunc-req}
\begin{quote}
  Everything about mode and transparencies:
  availability, mobility, security, fault tolerance, etc.
  Are there execution time bounds? Minimum data rates?

  If requested, specific platforms/languages/middlewares requirements
  for the implementation can be decided here.
  (E.g.: if the project is on a SOA, we may request that functions
  are offered via SOAP or RESTful services).
\end{quote}

In questa sezione analizziamo le caratteristiche non funzionali
che il sistema sarà in grado di offrire.

\subsubsection*{Scalabilità e trasparenza}
I sensori costituiranno una rete peer-to-peer,
senza alcuna suddivisione di ruoli a priori: i ruoli centralizzati
sono definiti staticamente con il compito fissato di fornire un punto
di accesso al cluster in ingresso (proponendo una nuova query) e
in uscita (raccogliendo informazioni relative alla riuscita
o al fallimento della query).

Un fondamentale requisito è che
la \emph{conoscenza} del grafo complessivo sia totalmente distribuita:
data la sua potenziale grandezza
non viene ricostruita alcuna descrizione centralizzata di essa.
Il sistema deve essere dunque scalabile e flessibile:
si devono poter aggiungere nuovi sensori o far spostare
quelli già presenti nella rete, senza la necessità di riconfigurare nulla.
L'implementazione delle
comunicazioni tra i punti di accesso centrali al cluster e
tra gli elementi stessi del cluster, potrà
sfruttare le catatteristiche offerte da \emph{Akka}:
scala con il numero di sensori e
deve essere svincolata dal conoscere la posizione dei singoli sensori.
Il grado di \emph{location transparency} offerto deve dunque essere molto elevato.

La gestione della conoscenza del grafo deve poter
sfruttare la scalabilità del sistema: quando nuovi sensori vengono
aggiunti, o quando si muovono quelli già presenti, si acquisiscono
nuove informazioni che devono essere utilizzabili dalle query successive.

\subsubsection*{Balancing}
La risoluzione del problema e la ricostruzione del sottografo
comporta intrinsecamente l'esplorazione progressiva e sequenziale
dei sensori che hanno informazioni rilevanti per la query.
Sono quindi le caratteristiche proprie del problema a impedire di
parallelizzare il lavoro nel sistema distribuito:
per ogni ricerca si avrà un solo nodo attivo alla volta.

La cifra dell'algoritmo distribuito sta dunque nella
condivisione di conoscenza, piuttosto che nella suddivisione del lavoro.
%% Inoltre,
%% il percorso di esplorazione della query, progressivamente snellita,
%% non influisce nella sua determinazione: una qualunque delle n! possibili
%% permutazioni -- qualunque sia l'ordine in cui la query attraversa i nodi --
%% trova la stessa soluzione, che richiede l'intervento SEQUENZIALE di
%% tutti i nodi che possono dire qualcosa sulla query stessa.
%% Dunque, dal punto di vista della correttezza dell'algoritmo,
%% a meno di failure, possiamo far procedere una sola query alla volta.

\subsubsection*{Failure model}
Trattandosi di query potenzialmente molto lunghe da verificare,
da gestirsi in modo sequenziale su un numero potenzialmente alto di sensori,
siamo disposti ad aggiungere uno scambio di messaggi non direttamente
informativi per quanto riguarda la ricerca: l'obiettivo è essere in grado
in caso di fallimenti di recuperare la query parziale,
evitando di perdere il lavoro eseguito fino a quel momento.

Occorre infatti tenere in considerazione i fallimenti legati alla rete e i
fallimenti legati ai sensori stessi.

Per proteggersi dalla perdita di messaggi da parte di una rete inaffidabile,
all'invio della query durante la ricerca, il mittente aspetterà un messaggio
di \emph{acknowledgement}: questo comporta dover definire un timeout
di attesa massima prima di stabilire che il messaggio è andato perduto
(e dunque che è necessario reinviarlo).
Bisogna tenere presente che
tale soluzione espone a casi di duplice invio della stessa query,
quando è il messaggio di \emph{ack} ad essere perso dalla rete.

Per proteggersi da casi di fallimento e morte dei sensori,
si utilizzerà una strategia di supervisione \emph{one-to-one}
per cui ogni sensore avrà un supervisore in grado di riattivarlo.
La ricerca può essere intaccata da fallimenti di questo tipo
quando il sensore muore nel momento in cui sta elaborando
nuove ipotesi sulla query attiva.
Copiare una versione della query parziale nel supervisore del nodo,
limita la finestra temporale in cui può accadere questo fallimento
critico.
Possiamo ulteriormente proteggere il sistema facendo procedere
un numero $k$ costante (3 di default) di query contemporaneamente.
La ridondanza introdotta, come già discusso,
non può essere una forma di parallelizzazione del lavoro: avere
più ricerche attive nello stesso momento permette unicamente di
aumentare le possibilità che una di queste riesca ad esplorare
tutto lo spazio dei sensori senza incontrare i (già limitati)
fallimenti critici ai quali il sistema rimane soggetto.
%% Questi ultimi infatti, hanno nel caso pessimo l'effetto di
%% rendere la corrispondente ricerca inattiva: quando una delle versioni
%% arriva alla conclusione, sblocca quelle che eventualmente sono rimaste
%% bloccate in questo stato.

Nel malaugurato caso in cui tutte le $k$ ricerche incontrino
fallimenti critici, il sistema risulterà bloccato: pur non potendo
distinguere tale sospensione dalla fase di ricerca, si affida
la responsabilità all'utente di terminare la ricerca manualmente.

\subsubsection*{Correttezza del risultato}
Senza fallimenti, il sistema deve riusire a rispondere con un messaggio di
\texttt{MATCH} / \texttt{FAIL} / \texttt{DONTKNOW} correttamente
rispetto a quanto definito nelle specifiche funzionali.
In generale, si garantisce che,
il sistema non dà falsi \texttt{MATCH} o falsi \texttt{FAIL} della query:
viene ammessa solo la restituzione di un falso \texttt{DONTKNOW}.

Infatti,
in caso di fallimenti può accadere che il sistema, sebbene la somma
delle conoscenze parziali sia in grado di definire un risultato,
risponda comunque \texttt{DONTKNOW} all'utente.

Quando la conoscenza dei sensori aumenta,
non è garantito che le nuove informazioni possano essere immediatamente
utilizzate se queste sono state acquisite \emph{durante} la fase di verifica
di una query: anche in questo caso, il sistema può rispondere eventualmente
\texttt{DONTKNOW}, anche quando l'insieme (aggiornato) delle conoscenze parziali
dei sensori sarebbe in grado di dare una risposta più specifica.

%%%%%%%%%%%%%%%%%%%%
\end{document}
